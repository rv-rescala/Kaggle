{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Simple MRA"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BASE_OUTPUT_PATH: ../output\n","BASE_INPUT_PATH: ../kaggle/input/optiver-trading-at-the-close\n","TRAIN_FILE: ../kaggle/input/optiver-trading-at-the-close/train.csv\n","TEST_FILE: ../kaggle/input/optiver-trading-at-the-close/test.csv\n","IS_OFFLINE: True\n"]}],"source":["from pathlib import Path\n","import os\n","import warnings\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","PREV_MAX = 80\n","if os.environ.get(\"KAGGLE_DATA_PROXY_TOKEN\") != None:\n","    BASE_OUTPUT_PATH = Path(f'/kaggle/working')\n","    BASE_INPUT_PATH = Path(f'/kaggle/input/optiver-trading-at-the-close')\n","    TRAIN_FILE = Path(f'{BASE_INPUT_PATH}/train.csv')\n","    TEST_FILE = Path(f'{BASE_INPUT_PATH}/test.csv')\n","    IS_OFFLINE = False\n","\n","    # subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"talib_binary\", \"--no-index\", \"--find-links\", \"file:///kaggle/input/ta-lib/\"])\n","else:\n","    BASE_OUTPUT_PATH = Path(f'../output')\n","    BASE_INPUT_PATH = Path(f'../kaggle/input/optiver-trading-at-the-close')\n","    TRAIN_FILE = Path(f'{BASE_INPUT_PATH}/train.csv')\n","    TEST_FILE = Path(f'{BASE_INPUT_PATH}/test.csv')\n","    SAMPLE_SUBMISSION_FILE = Path(f'{BASE_INPUT_PATH}/sample_submission.csv')\n","    REVEALED_TARGETS_FILE = Path(f'{BASE_INPUT_PATH}/revealed_targets.csv')\n","    IS_OFFLINE = True\n","print(f\"BASE_OUTPUT_PATH: {BASE_OUTPUT_PATH}\")\n","print(f\"BASE_INPUT_PATH: {BASE_INPUT_PATH}\")\n","print(f\"TRAIN_FILE: {TRAIN_FILE}\")\n","print(f\"TEST_FILE: {TEST_FILE}\")\n","print(f\"IS_OFFLINE: {IS_OFFLINE}\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from typing import Sequence, Tuple\n","\n","import pandas as pd\n","\n","\n","class MockApi:\n","    def __init__(self):\n","        '''\n","        YOU MUST UPDATE THE FIRST THREE LINES of this method.\n","        They've been intentionally left in an invalid state.\n","\n","        Variables to set:\n","            input_paths: a list of two or more paths to the csv files to be served\n","            group_id_column: the column that identifies which groups of rows the API should serve.\n","                A call to iter_test serves all rows of all dataframes with the current group ID value.\n","            export_group_id_column: if true, the dataframes iter_test serves will include the group_id_column values.\n","        '''\n","        self.input_paths: Sequence[str] = [TEST_FILE, REVEALED_TARGETS_FILE, SAMPLE_SUBMISSION_FILE]\n","        self.group_id_column: str = 'time_id'\n","        self.export_group_id_column: bool = True\n","        # iter_test is only designed to support at least two dataframes, such as test and sample_submission\n","        assert len(self.input_paths) >= 2\n","\n","        self._status = 'initialized'\n","        self.predictions = []\n","\n","    def iter_test(self) -> Tuple[pd.DataFrame]:\n","        '''\n","        Loads all of the dataframes specified in self.input_paths,\n","        then yields all rows in those dataframes that equal the current self.group_id_column value.\n","        '''\n","        if self._status != 'initialized':\n","\n","            raise Exception('WARNING: the real API can only iterate over `iter_test()` once.')\n","\n","        dataframes = []\n","        for pth in self.input_paths:\n","            dataframes.append(pd.read_csv(pth, low_memory=False))\n","        group_order = dataframes[0][self.group_id_column].drop_duplicates().tolist()\n","        dataframes = [df.set_index(self.group_id_column) for df in dataframes]\n","\n","        for group_id in group_order:\n","            self._status = 'prediction_needed'\n","            current_data = []\n","            for df in dataframes:\n","                cur_df = df.loc[group_id].copy()\n","                # returning single line dataframes from df.loc requires special handling\n","                if not isinstance(cur_df, pd.DataFrame):\n","                    cur_df = pd.DataFrame({a: b for a, b in zip(cur_df.index.values, cur_df.values)}, index=[group_id])\n","                    cur_df.index.name = self.group_id_column\n","                cur_df = cur_df.reset_index(drop=not(self.export_group_id_column))\n","                current_data.append(cur_df)\n","            yield tuple(current_data)\n","\n","            while self._status != 'prediction_received':\n","                print('You must call `predict()` successfully before you can continue with `iter_test()`', flush=True)\n","                yield None\n","\n","        with open('submission.csv', 'w') as f_open:\n","            pd.concat(self.predictions).to_csv(f_open, index=False)\n","        self._status = 'finished'\n","\n","    def predict(self, user_predictions: pd.DataFrame):\n","        '''\n","        Accepts and stores the user's predictions and unlocks iter_test once that is done\n","        '''\n","        if self._status == 'finished':\n","            raise Exception('You have already made predictions for the full test set.')\n","        if self._status != 'prediction_needed':\n","            raise Exception('You must get the next test sample from `iter_test()` first.')\n","        if not isinstance(user_predictions, pd.DataFrame):\n","            raise Exception('You must provide a DataFrame.')\n","\n","        self.predictions.append(user_predictions)\n","        self._status = 'prediction_received'\n","\n","\n","def make_env():\n","    return MockApi()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-09T05:08:20.201019Z","iopub.status.busy":"2023-11-09T05:08:20.200350Z","iopub.status.idle":"2023-11-09T05:08:38.282998Z","shell.execute_reply":"2023-11-09T05:08:38.281934Z","shell.execute_reply.started":"2023-11-09T05:08:20.200957Z"},"trusted":true},"outputs":[],"source":["train_dataset = pd.read_csv(TRAIN_FILE)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["features = ['imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'matched_size', \n","            'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n","\n","train_dataset_drop = train_dataset[features+['target', 'stock_id']].dropna()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["     const  imbalance_size  imbalance_buy_sell_flag  reference_price  \\\n","0      1.0      3180602.69                        1         0.999812   \n","191    1.0      1299772.70                        1         1.000026   \n","382    1.0      1299772.70                        1         0.999919   \n","573    1.0      1299772.70                        1         1.000133   \n","764    1.0      1218204.43                        1         1.000455   \n","\n","     matched_size  bid_price  bid_size  ask_price  ask_size       wap  \n","0     13380276.64   0.999812  60651.50   1.000026   8493.03  1.000000  \n","191   15261106.63   0.999812  13996.50   1.000026  23519.16  0.999892  \n","382   15261106.63   0.999812   4665.50   0.999919  12131.60  0.999842  \n","573   15261106.63   1.000026  55998.00   1.000133  46203.30  1.000085  \n","764   15342674.90   1.000241  14655.95   1.000455  26610.45  1.000317  \n","(26455, 10)\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 26455 entries, 0 to 5237780\n","Data columns (total 10 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   const                    26455 non-null  float64\n"," 1   imbalance_size           26455 non-null  float64\n"," 2   imbalance_buy_sell_flag  26455 non-null  int64  \n"," 3   reference_price          26455 non-null  float64\n"," 4   matched_size             26455 non-null  float64\n"," 5   bid_price                26455 non-null  float64\n"," 6   bid_size                 26455 non-null  float64\n"," 7   ask_price                26455 non-null  float64\n"," 8   ask_size                 26455 non-null  float64\n"," 9   wap                      26455 non-null  float64\n","dtypes: float64(9), int64(1)\n","memory usage: 2.2 MB\n","None\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","import statsmodels.api as sm\n","\n","# 重回帰モデルの結果を格納するための辞書\n","model_stats = {}\n","models = {}\n","\n","# 'stock_id'ごとにデータをループ処理\n","for stock_id, group_data in train_dataset_drop.groupby('stock_id'):\n","    # 目的変数と説明変数の分離\n","    X = group_data[features]\n","    y = group_data['target']\n","\n","    # 説明変数に定数項（切片）を追加\n","    X = sm.add_constant(X)\n","\n","    if stock_id == 0:\n","        print(X.head())\n","        print(X.shape)\n","        print(X.info())\n","\n","    # OLS（最小二乗法）モデルの訓練\n","    model = sm.OLS(y, X).fit()\n","\n","    # 重回帰モデルによる予測値の算出\n","    y_pred = model.predict(X)\n","    train_dataset_drop.loc[train_dataset_drop['stock_id'] == stock_id, 'target'] = y_pred\n","\n","    # 各種統計値の取得\n","    aic = model.aic\n","    f_stat = model.fvalue\n","    r_squared = model.rsquared\n","\n","    # 統計値を辞書に保存\n","    model_stats[stock_id] = {'AIC': aic, 'F-Statistic': f_stat, 'R-Squared': r_squared}\n","    # モデルを辞書に保存\n","    models[stock_id] = model\n"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'float' object has no attribute 'dtype'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m         predictions\u001b[39m.\u001b[39mextend([\u001b[39m0.0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(group))\n\u001b[1;32m     29\u001b[0m \u001b[39m# sample_prediction に予測結果をセット\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mprint\u001b[39m(predictions[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m     31\u001b[0m sample_prediction[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m predictions\n\u001b[1;32m     34\u001b[0m \u001b[39m# 予測を提出\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'dtype'"]}],"source":["if IS_OFFLINE:\n","    env = make_env()\n","else:\n","    import optiver2023\n","    env = optiver2023.make_env()\n","iter_test = env.iter_test()\n","\n","\n","for (test, revealed_targets, sample_prediction) in iter_test:\n","    # 特徴量を追加し、stock_id でグループ化\n","    test = sm.add_constant(test[features + ['stock_id']], has_constant='add')\n","    grouped = test.groupby('stock_id', sort=True)  # stock_id でグループ化し、同時にソート\n","\n","    predictions = []\n","\n","    for stock_id, group in grouped:\n","        model = models.get(stock_id, None)\n","        if model is not None:\n","            # stock_id ごとの特徴量を取得\n","            X = group.drop(columns=['stock_id'])\n","\n","            # モデルを使用して予測\n","            stock_predictions = model.predict(X)\n","            predictions.extend(stock_predictions)\n","        else:\n","            # stock_id に対応するモデルがない場合、デフォルトの値を設定\n","            predictions.extend([0.0] * len(group))\n","\n","    # sample_prediction に予測結果をセット\n","    print(type(predictions[0]))\n","    sample_prediction['target'] = predictions\n","    \n","\n","    # 予測を提出\n","    env.predict(sample_prediction)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
